{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mbuSV4qYluIW",
        "Gfa95vj_HqOk",
        "-7hpg8N-ncen",
        "Xnn9lTlhnfBw",
        "yaV3wVNzv1uo",
        "nXCD737KM3fZ",
        "GYKFgRqvQ2-O"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbuSV4qYluIW"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86EmSWPHm1YO"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd ./drive/MyDrive/CS194-26/Proj2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-Ow3C4_BQxi"
      },
      "source": [
        "%pylab inline\n",
        "\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import skimage as sk\n",
        "from skimage import transform\n",
        "import skimage.io as skio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "!pip install line_profiler\n",
        "%load_ext line_profiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gfa95vj_HqOk"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auubn-bpHrFg"
      },
      "source": [
        "def get_image(path):\n",
        "  im = imread(path)\n",
        "  im = im.astype(float)\n",
        "  return im\n",
        "\n",
        "def show(im, figsize = 10, cmap=None):\n",
        "  # Uses matplotlib in the backend to show images\n",
        "  figure(figsize=(figsize,figsize))\n",
        "  imshow(im, cmap=cmap)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7hpg8N-ncen"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nvabFCxMyen"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osMioD5lMu73"
      },
      "source": [
        "from scipy.signal import convolve2d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xnn9lTlhnfBw"
      },
      "source": [
        "## 1.1 Finite Difference Operator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qum6BjdDnNxa"
      },
      "source": [
        "cameraman = get_image('cameraman.png')\n",
        "dX = np.array([[-1, 1]])\n",
        "dY = np.array([[1], [-1]])\n",
        "\n",
        "\n",
        "show(cameraman, cmap = 'gray', figsize = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTwl4s9XoO3a"
      },
      "source": [
        "edge_x = convolve2d(cameraman[:,:,0], dX, mode = 'same', boundary = 'fill')\n",
        "show(edge_x, cmap = 'gray')\n",
        "plt.title('D_x')\n",
        "\n",
        "edge_y = convolve2d(cameraman[:,:,0], dY, mode = 'same', boundary = 'fill')\n",
        "show(edge_y, cmap = 'gray')\n",
        "plt.title('D_y')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9rtdoHYw5aL"
      },
      "source": [
        "edges = np.sqrt(edge_x**2 + edge_y**2)\n",
        "show(edges, cmap = 'gray')\n",
        "plt.title('Gradient Magnitude')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vJ416qBst-3"
      },
      "source": [
        "For this threshold value, the best is somewhere between .15 and .18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDl6SumNowcX"
      },
      "source": [
        "fig, axs = fig, ax = plt.subplots(5, 2, figsize=(15, 40))\n",
        "increment = .04\n",
        "for i in range(10):\n",
        "  edges = np.sqrt(edge_x**2 + edge_y**2)\n",
        "  threshold = increment * i\n",
        "  edges = edges > threshold\n",
        "  axs[i//2, i % 2].imshow(edges, cmap = 'gray')\n",
        "  axs[i//2, i % 2].set_title('Threshold: ' + str(increment * i))\n",
        "\n",
        "fig.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaV3wVNzv1uo"
      },
      "source": [
        "## 1.2 DoG Filter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J57KG17H9Lo3"
      },
      "source": [
        "**NOTE**: We are using an odd sized gaussian kernel since convolving D_x * G would otherwise be lopsided due to edge behavior"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aQ7fDFDyj5H"
      },
      "source": [
        "There aren't any real noticable differences between the original image and this one... just slightly blurrier\n",
        "\n",
        "To do all this, we just blur the original image, and then do the same derivative filters that we did before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjVFru_IqCop"
      },
      "source": [
        "k_size = 12\n",
        "G = cv2.getGaussianKernel(k_size, 1) @ cv2.getGaussianKernel(k_size, 1).T\n",
        "cameraman_blur = convolve2d(cameraman[:,:,0], G, mode = 'same', boundary = 'fill')\n",
        "show(cameraman_blur, cmap = 'gray')\n",
        "plt.title('Cameraman Blurred')\n",
        "edge_x = convolve2d(cameraman_blur, dX, mode = 'same', boundary = 'fill')\n",
        "edge_y = convolve2d(cameraman_blur, dY, mode = 'same', boundary = 'fill')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_ysHhynqZ_H"
      },
      "source": [
        "edges = np.sqrt(edge_x**2 + edge_y**2)\n",
        "\n",
        "show(edges, cmap = 'gray')\n",
        "plt.title('Gradient Magnitude (Blurred)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHtXRh9Uzrqq"
      },
      "source": [
        "For this threshold value, the best is somewhere between .15 and .18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlyL6LpWzrqq"
      },
      "source": [
        "fig, axs = fig, ax = plt.subplots(5, 2, figsize=(15, 40))\n",
        "increment = .01\n",
        "for i in range(10):\n",
        "  edges = np.sqrt(edge_x**2 + edge_y**2)\n",
        "  threshold = increment * i\n",
        "  edges = edges > threshold\n",
        "  axs[i//2, i % 2].imshow(edges, cmap = 'gray')\n",
        "  axs[i//2, i % 2].set_title('Threshold: ' + str(increment * i))\n",
        "\n",
        "fig.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BqkraLDzCLx"
      },
      "source": [
        "Now Using (G * derivatives) * image\n",
        "\n",
        "To do this, we will take our even sized gaussian kernel (larger gets better edge behavior) and we will convolve dx (np.array([[1, -1]]) over G and dy (np.array([[1],[-1]])) over G, taking the magnitude of both gradients to get out edges"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORfmO8a2xW92"
      },
      "source": [
        "G = cv2.getGaussianKernel(k_size, 1) @ cv2.getGaussianKernel(k_size, 1).T\n",
        "G_dx = convolve2d(G, np.array([[1, -1]]), mode = 'same', boundary = 'fill')\n",
        "G_dy = convolve2d(G, np.array([[-1],[1]]), mode = 'same', boundary = 'fill')\n",
        "\n",
        "edge_x = convolve2d(cameraman[:,:,0], G_dx, mode = 'same', boundary = 'fill')\n",
        "edge_y = convolve2d(cameraman[:,:,0], G_dy, mode = 'same', boundary = 'fill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtuOYRFm0M0o"
      },
      "source": [
        "Gradient Magnitude Blurred (G * derivatives) * image\n",
        "\n",
        "Qualitativley, this looks the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8MgKgDnzeJ-"
      },
      "source": [
        "edges = np.sqrt(edge_x**2 + edge_y**2)\n",
        "show(edges, cmap = 'gray')\n",
        "plt.title('Gradient Magnitude (Blurred)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hB32xcR0g2I"
      },
      "source": [
        "Thresholding with (G * derivatives) * image\n",
        "\n",
        "Qualitativley, still looks the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWEwkRnU0TFM"
      },
      "source": [
        "fig, axs = fig, ax = plt.subplots(5, 2, figsize=(15, 40))\n",
        "increment = .01\n",
        "for i in range(10):\n",
        "  edges = np.sqrt(edge_x**2 + edge_y**2)\n",
        "  threshold = increment * i\n",
        "  edges = edges > threshold\n",
        "  axs[i//2, i % 2].imshow(edges, cmap = 'gray')\n",
        "  axs[i//2, i % 2].set_title('Threshold: ' + str(increment * i))\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fugW5Lp58Aoc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYJn3dMl9lME"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vi8u8vTkM04p"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbkvDGCC9mJl"
      },
      "source": [
        "from scipy.fft import fft2, ifft2\n",
        "import align_image_code\n",
        "from align_image_code import align_images\n",
        "\n",
        "import matplotlib\n",
        "%matplotlib\n",
        "# make align_images call here\n",
        "%matplotlib inline\n",
        "#matplotlib.use('TkAgg')\n",
        "\n",
        "\n",
        "def fft_magnitude(img):\n",
        "  return np.absolute(fft2(img))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform as sktr\n",
        "\n",
        "\n",
        "\n",
        "def get_points(im1, im2):\n",
        "    print('Please select 2 points in each image for alignment.')\n",
        "    plt.imshow(im1)\n",
        "    p1, p2 = plt.ginput(2)\n",
        "    plt.close()\n",
        "    plt.imshow(im2)\n",
        "    p3, p4 = plt.ginput(2)\n",
        "    plt.close()\n",
        "    return (p1, p2, p3, p4)\n",
        "\n",
        "def recenter(im, r, c):\n",
        "    R, C, _ = im.shape\n",
        "    rpad = (int) (np.abs(2*r+1 - R))\n",
        "    cpad = (int) (np.abs(2*c+1 - C))\n",
        "    return np.pad(\n",
        "        im, [(0 if r > (R-1)/2 else rpad, 0 if r < (R-1)/2 else rpad),\n",
        "             (0 if c > (C-1)/2 else cpad, 0 if c < (C-1)/2 else cpad),\n",
        "             (0, 0)], 'constant')\n",
        "\n",
        "def find_centers(p1, p2):\n",
        "    cx = np.round(np.mean([p1[0], p2[0]]))\n",
        "    cy = np.round(np.mean([p1[1], p2[1]]))\n",
        "    return cx, cy\n",
        "\n",
        "def align_image_centers(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    h1, w1, b1 = im1.shape\n",
        "    h2, w2, b2 = im2.shape\n",
        "    \n",
        "    cx1, cy1 = find_centers(p1, p2)\n",
        "    cx2, cy2 = find_centers(p3, p4)\n",
        "\n",
        "    im1 = recenter(im1, cy1, cx1)\n",
        "    im2 = recenter(im2, cy2, cx2)\n",
        "    return im1, im2\n",
        "\n",
        "def rescale_images(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    len1 = np.sqrt((p2[1] - p1[1])**2 + (p2[0] - p1[0])**2)\n",
        "    len2 = np.sqrt((p4[1] - p3[1])**2 + (p4[0] - p3[0])**2)\n",
        "    dscale = len2/len1\n",
        "    if dscale < 1:\n",
        "        im1 = sktr.rescale(im1, dscale, multichannel=True)\n",
        "    else:\n",
        "        im2 = sktr.rescale(im2, 1./dscale, multichannel=True)\n",
        "    return im1, im2\n",
        "\n",
        "def rotate_im1(im1, im2, pts):\n",
        "    p1, p2, p3, p4 = pts\n",
        "    theta1 = math.atan2(-(p2[1] - p1[1]), (p2[0] - p1[0]))\n",
        "    theta2 = math.atan2(-(p4[1] - p3[1]), (p4[0] - p3[0]))\n",
        "    dtheta = theta2 - theta1\n",
        "    im1 = sktr.rotate(im1, dtheta*180/np.pi)\n",
        "    return im1, dtheta\n",
        "\n",
        "def match_img_size(im1, im2):\n",
        "    # Make images the same size\n",
        "    h1, w1, c1 = im1.shape\n",
        "    h2, w2, c2 = im2.shape\n",
        "    if h1 < h2:\n",
        "        im2 = im2[int(np.floor((h2-h1)/2.)) : -int(np.ceil((h2-h1)/2.)), :, :]\n",
        "    elif h1 > h2:\n",
        "        im1 = im1[int(np.floor((h1-h2)/2.)) : -int(np.ceil((h1-h2)/2.)), :, :]\n",
        "    if w1 < w2:\n",
        "        im2 = im2[:, int(np.floor((w2-w1)/2.)) : -int(np.ceil((w2-w1)/2.)), :]\n",
        "    elif w1 > w2:\n",
        "        im1 = im1[:, int(np.floor((w1-w2)/2.)) : -int(np.ceil((w1-w2)/2.)), :]\n",
        "    assert im1.shape == im2.shape\n",
        "    return im1, im2\n",
        "\n",
        "def align_images(im1, im2):\n",
        "    pts = get_points(im1, im2)\n",
        "    im1, im2 = align_image_centers(im1, im2, pts)\n",
        "    im1, im2 = rescale_images(im1, im2, pts)\n",
        "    im1, angle = rotate_im1(im1, im2, pts)\n",
        "    im1, im2 = match_img_size(im1, im2)\n",
        "    return im1, im2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXCD737KM3fZ"
      },
      "source": [
        "## 2.1 Image \"Sharpening\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIMVHAbn5Dtf"
      },
      "source": [
        "Naive sharpen is the way of sharpening an image by doing a bunch of operations, adding the high pass scaled by alpha to the original image\n",
        "\n",
        "Fast sharpen is the combined version where we do everything in a single convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ngWLK70M2Gk"
      },
      "source": [
        "def naive_sharpen(image, k_size, alpha=.1, g_std = 1):\n",
        "  G = cv2.getGaussianKernel(k_size, g_std) @ cv2.getGaussianKernel(k_size, g_std).T\n",
        "  low_pass = convolve2d(image, G, mode='same')\n",
        "  high_pass = image - low_pass\n",
        "\n",
        "  return np.clip(image + alpha * high_pass, 0, 1)\n",
        "\n",
        "def fast_sharpen(image, k_size, alpha=.1, g_std=1):\n",
        "  G = cv2.getGaussianKernel(k_size, g_std) @ cv2.getGaussianKernel(k_size, g_std).T\n",
        "  #make an identity conv with just a one in the center... same size as gaussian kernel. Special case for even sized\n",
        "  # gaussian kernel, since the placement of the one will effect whether or not it is truly the identity conv\n",
        "  # for a \"same\" convolution\n",
        "  if not k_size % 2:\n",
        "    identity_conv = np.zeros((k_size, k_size))\n",
        "    identity_conv[k_size//2, k_size//2] = 1\n",
        "  else:\n",
        "    identity_conv = np.zeros((k_size, k_size))\n",
        "    identity_conv[k_size//2 + 1, k_size//2 + 1] = 1\n",
        "\n",
        "  combined_kernel = (1 + alpha) * identity_conv - alpha * G\n",
        "  conv = convolve2d(image, combined_kernel, mode = 'same')\n",
        "\n",
        "  return np.clip(conv, 0, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3jClmoL-AsN"
      },
      "source": [
        "The control. Just the regular image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPnuvPOk9-n4"
      },
      "source": [
        "show(cameraman[:,:,0], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xA9pmBPk-D3h"
      },
      "source": [
        "Naive sharpening (not done all in one kernel)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX_YkQc-8YXW"
      },
      "source": [
        "show(naive_sharpen(cameraman[:,:,0], 11, .5), cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LGSuWMC97xS"
      },
      "source": [
        "Clearly the fast sharpening works, since the output is the same as the naive way"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dCtiM_98Zo4"
      },
      "source": [
        "show(fast_sharpen(cameraman[:,:,0], 11, .5), cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTm7NIj996zZ"
      },
      "source": [
        "Working with some custom images\n",
        "\n",
        "The results are pretty good. Colors arent unbalanced or anything, and background/blurry features come more into view. I suspect though that if I had a larger screen to view these images on, I would find the result less appealing since the sharpening would definitley make smaller features come more into view, distracting me from the primary object in the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkyySY5Z-X7v"
      },
      "source": [
        "im = get_image('taj.jpeg')/255\n",
        "sharpened = np.stack([fast_sharpen(im[:,:,i], 11, .7) for i in range(3)], axis=-1)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(24, 24))\n",
        "\n",
        "axs[0].imshow(im, cmap = 'gray')\n",
        "axs[0].set_title(\"Unsharpened\")\n",
        "axs[1].imshow(sharpened, cmap = 'gray')\n",
        "axs[1].set_title(\"Sharpened\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_G42y-_AX0i"
      },
      "source": [
        "im = get_image('beautiful_world.jpg')/255\n",
        "sharpened = np.stack([fast_sharpen(im[:,:,i], 11, .7) for i in range(3)], axis=-1)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(24, 24))\n",
        "\n",
        "axs[0].imshow(im, cmap = 'gray')\n",
        "axs[0].set_title(\"Unsharpened\")\n",
        "axs[1].imshow(sharpened, cmap = 'gray')\n",
        "axs[1].set_title(\"Sharpened\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BHoBkFJAvT6"
      },
      "source": [
        "im = get_image('red.jpg')/255\n",
        "sharpened = np.stack([fast_sharpen(im[:,:,i], 11, .9) for i in range(3)], axis=-1)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(24, 24))\n",
        "\n",
        "axs[0].imshow(im, cmap = 'gray')\n",
        "axs[0].set_title(\"Unsharpened\")\n",
        "axs[1].imshow(sharpened, cmap = 'gray')\n",
        "axs[1].set_title(\"Sharpened\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACdFCGlRBdj0"
      },
      "source": [
        "im = get_image('miracles.jpg')/255\n",
        "sharpened = np.stack([fast_sharpen(im[:,:,i], 11, .7) for i in range(3)], axis=-1)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(24, 24))\n",
        "\n",
        "axs[0].imshow(im, cmap = 'gray')\n",
        "axs[0].set_title(\"Unsharpened\")\n",
        "axs[1].imshow(sharpened, cmap = 'gray')\n",
        "axs[1].set_title(\"Sharpened\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqBkia_kBp5L"
      },
      "source": [
        "im = get_image('temple.jpg')/255\n",
        "sharpened = np.stack([fast_sharpen(im[:,:,i], 11, .7) for i in range(3)], axis=-1)\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(24, 24))\n",
        "\n",
        "axs[0].imshow(im, cmap = 'gray')\n",
        "axs[0].set_title(\"Unsharpened\")\n",
        "axs[1].imshow(sharpened, cmap = 'gray')\n",
        "axs[1].set_title(\"Sharpened\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cmUqd9j6EumD"
      },
      "source": [
        "show(sharpened, figsize=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOlDkPGENBOs"
      },
      "source": [
        "## 2.2 Hybrid Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kumZWnSBHNGR"
      },
      "source": [
        "Here, the idea is that we add the weighted high pass and the weighted low pass, getting our final image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EoUa33PNC4x"
      },
      "source": [
        "def hybrid_image(image_high, image_low, k_size=11, alpha=.5, g_std=1):\n",
        "  G = cv2.getGaussianKernel(k_size, g_std) @ cv2.getGaussianKernel(k_size, g_std).T\n",
        "  if not k_size % 2:\n",
        "    identity_conv = np.zeros((k_size, k_size))\n",
        "    identity_conv[k_size//2, k_size//2] = 1\n",
        "  else:\n",
        "    identity_conv = np.zeros((k_size, k_size))\n",
        "    identity_conv[k_size//2 + 1, k_size//2 + 1] = 1\n",
        "\n",
        "  high_pass_kernel = identity_conv - (G)\n",
        "  low_pass_kernel = G\n",
        "\n",
        "  high_pass = convolve2d(image_high, high_pass_kernel, 'same')\n",
        "  low_pass = convolve2d(image_low, low_pass_kernel, 'same')\n",
        "\n",
        "  return np.clip(high_pass * alpha + low_pass * (1-alpha), 0, 1)\n",
        "\n",
        "def hybrid_uncombined(image_high, image_low, k_size=11, alpha=.5, g_std=1):\n",
        "  G = cv2.getGaussianKernel(k_size, g_std) @ cv2.getGaussianKernel(k_size, g_std).T\n",
        "  if not k_size % 2:\n",
        "    identity_conv = np.zeros((k_size, k_size))\n",
        "    identity_conv[k_size//2, k_size//2] = 1\n",
        "  else:\n",
        "    identity_conv = np.zeros((k_size, k_size))\n",
        "    identity_conv[k_size//2 + 1, k_size//2 + 1] = 1\n",
        "\n",
        "  high_pass_kernel = identity_conv - (G)\n",
        "  low_pass_kernel = G\n",
        "\n",
        "  high_pass = convolve2d(image_high, high_pass_kernel, 'same')\n",
        "  low_pass = convolve2d(image_low, low_pass_kernel, 'same')\n",
        "\n",
        "  return high_pass, low_pass\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7lhrlaSHZON"
      },
      "source": [
        "im_high = get_image('nutmeg.jpg')/255\n",
        "im_low = get_image('DerekPicture.jpg')/255\n",
        "\n",
        "pts = ((752, 373), (607, 287), (445, 333), (305, 348))\n",
        "\n",
        "im_high, im_low = align_image_centers(im_high, im_low, pts)\n",
        "im_high, im_low = rescale_images(im_high, im_low, pts)\n",
        "im_high, angle = rotate_im1(im_high, im_low, pts)\n",
        "im_high, im_low = match_img_size(im_high, im_low)\n",
        "show(hybrid_image(np.mean(im_high, -1), np.mean(im_low, -1), alpha=.65, k_size=25, g_std=10), cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsSj0tncmW8N"
      },
      "source": [
        "See the filtering in action!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2XRpVojmWWK"
      },
      "source": [
        "im_high = cv2.resize(get_image('pickup.jpeg')/255, (1100, 600))\n",
        "im_low = cv2.resize(get_image('cybertruck.jpeg')/255, (1100, 600))\n",
        "\n",
        "im_high_original = im_high\n",
        "im_low_original = im_low\n",
        "\n",
        "pts = ((222, 388), (824, 382), (180, 427), (881, 419))\n",
        "\n",
        "im_high, im_low = align_image_centers(im_high, im_low, pts)\n",
        "im_high, im_low = rescale_images(im_high, im_low, pts)\n",
        "im_high, angle = rotate_im1(im_high, im_low, pts)\n",
        "im_high, im_low = match_img_size(im_high, im_low)\n",
        "\n",
        "im_high_original = np.mean(im_high, -1)\n",
        "im_low_original = np.mean(im_low, -1)\n",
        "show(hybrid_image(np.mean(im_high, -1), np.mean(im_low, -1), alpha=.5, k_size=50, g_std=12), cmap = 'gray')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bShhIEgKs9xS"
      },
      "source": [
        "You can see that our wide gaussian only really filters the middle stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJEd5hK3qtdr"
      },
      "source": [
        "show(cv2.getGaussianKernel(100, 25) @ cv2.getGaussianKernel(100, 25).T)\n",
        "show((np.abs(np.fft.fftshift(np.fft.fft2(cv2.getGaussianKernel(100, 25) @ cv2.getGaussianKernel(100, 25).T)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrLFe4Agtdjj"
      },
      "source": [
        "You can see the large effect of our low pass filter (the bars remaining in the frequency domain are clearly from the fact that our image allignment leaves large black bars on our image that have such high amplitudes, that even a gaussian has difficulty removing them entirely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttrpOybBoamW"
      },
      "source": [
        "high_pass, low_pass = hybrid_uncombined(np.mean(im_high, -1), np.mean(im_low, -1), alpha=.5, k_size=50, g_std=12)\n",
        "fig, axs = plt.subplots(2, 4, figsize=(24, 12))\n",
        "axs[0, 0].imshow(im_high_original, cmap = 'gray')\n",
        "scale1 = np.max(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im_high_original)))))\n",
        "minscale1 = np.min(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im_high_original)))))\n",
        "axs[0, 1].imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im_high_original)))), cmap = 'gray', vmax=scale1, vmin = minscale1)\n",
        "axs[0, 2].imshow(high_pass, cmap = 'gray')\n",
        "axs[0, 3].imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(high_pass)))), cmap = 'gray', vmax=scale1, vmin = minscale1)\n",
        "axs[1, 0].imshow(im_low_original, cmap = 'gray')\n",
        "scale2 = np.max(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im_low_original)))))\n",
        "minscale2 = np.min(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im_low_original)))))\n",
        "axs[1, 1].imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(im_low_original)))), cmap = 'gray', vmax=scale2, vmin = minscale2)\n",
        "axs[1, 2].imshow(low_pass, cmap = 'gray')\n",
        "axs[1, 3].imshow(np.log(np.abs(np.fft.fftshift(np.fft.fft2(low_pass)))), cmap = 'gray', vmax=scale2, vmin=minscale2)\n",
        "\n",
        "fig.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN0N4DXCmXmf"
      },
      "source": [
        "See some other images become hybrids"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx3WHVgEM6hW"
      },
      "source": [
        "im_high = cv2.resize(get_image('pickup.jpeg')/255, (1100, 600))\n",
        "im_low = cv2.resize(get_image('cybertruck.jpeg')/255, (1100, 600))\n",
        "\n",
        "pts = ((222, 388), (824, 382), (180, 427), (881, 419))\n",
        "\n",
        "im_high, im_low = align_image_centers(im_high, im_low, pts)\n",
        "im_high, im_low = rescale_images(im_high, im_low, pts)\n",
        "im_high, angle = rotate_im1(im_high, im_low, pts)\n",
        "im_high, im_low = match_img_size(im_high, im_low)\n",
        "show(hybrid_image(np.mean(im_high, -1), np.mean(im_low, -1), alpha=.5, k_size=25, g_std=12), cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZi8BKHQWEnM"
      },
      "source": [
        "im_low = cv2.resize(get_image('cookie1.jpeg')/255, (900, 600))\n",
        "im_high = cv2.resize(get_image('cookie2.jpeg')/255, (900, 600))\n",
        "\n",
        "pts = ((14, 271), (479, 266), (274, 304), (645, 313))\n",
        "\n",
        "im_high, im_low = align_image_centers(im_high, im_low, pts)\n",
        "im_high, im_low = rescale_images(im_high, im_low, pts)\n",
        "im_high, angle = rotate_im1(im_high, im_low, pts)\n",
        "im_high, im_low = match_img_size(im_high, im_low)\n",
        "show(hybrid_image(np.mean(im_high, -1), np.mean(im_low, -1), alpha=.7, k_size=25, g_std=4), cmap = 'gray')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wm-KbLMUcft"
      },
      "source": [
        "Bells and Whistles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVGFLg49UeV6"
      },
      "source": [
        "Color seems to be finnickey. You clearly need some of both, but it can be really challenging to get the color balance while maintaining the image quality. I'm using mostly color from the high frequency image, with a little bit of the color from the low frequency image, but that can certainly be tweaked."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnljjDH6RP4V"
      },
      "source": [
        "im = np.stack([hybrid_image(im_high[:,:,i], im_low[:,:,i], alpha=.8, k_size=25, g_std=10) for i in range(3)], -1)\n",
        "show(im)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXmydaQ8NLQK"
      },
      "source": [
        "## 2.3 Gaussian and Lapacian Stacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0UqVyhSkIly"
      },
      "source": [
        "Here, we just append the current image to the smaller size stack that begins with the blurred current image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rmpt-6gNLh_"
      },
      "source": [
        "def gaussian_stack(image, levels, g_std = 1, k_size = 5):\n",
        "  image = np.copy(image)\n",
        "  if levels == 1:\n",
        "    return [image]\n",
        "  \n",
        "  G = cv2.getGaussianKernel(k_size, g_std) @ cv2.getGaussianKernel(k_size, g_std).T\n",
        "  if len(image.shape) > 2:\n",
        "    next_image = np.stack([convolve2d(image[:,:,i], G, mode = 'same') for i in range(3)], axis =-1)\n",
        "  else:\n",
        "    next_image = convolve2d(image, G, mode = 'same')\n",
        "\n",
        "\n",
        "  return [image] + gaussian_stack(next_image, levels - 1, g_std * 2, k_size + 7)\n",
        "\n",
        "def laplacian_stack(image, levels, g_std = 1, k_size = 5):\n",
        "  stack = gaussian_stack(image, levels, g_std, k_size)\n",
        "\n",
        "  for i in range(len(stack) - 1):\n",
        "    stack[i] = stack[i] - stack[i+1]\n",
        "\n",
        "  return stack\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MSuF2ixj6ja"
      },
      "source": [
        "Gaussian stack in action!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnl1UzBIbEXK"
      },
      "source": [
        "stack = gaussian_stack(cameraman[:,:,0], 5, g_std = 2, k_size=21)\n",
        "\n",
        "fig, axs = fig, ax = plt.subplots(1, 5, figsize=(24, 50))\n",
        "for i in range(5):\n",
        "  axs[i].imshow(stack[i], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26lZ8yYXubTy"
      },
      "source": [
        "Laplacian Stack in action!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RuTPol_uXi0"
      },
      "source": [
        "stack = laplacian_stack(cameraman[:,:,0], 5, g_std = 2, k_size=21)\n",
        "\n",
        "fig, axs = plt.subplots(1, 5, figsize=(24, 50))\n",
        "for i in range(5):\n",
        "  axs[i].imshow(stack[i], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8HGTG1Ixt4n"
      },
      "source": [
        "orange_stack = laplacian_stack(get_image('orange.jpeg')/255, 5, g_std = 2, k_size = 21)\n",
        "apple_stack = laplacian_stack(get_image('apple.jpeg')/255, 5, g_std = 2, k_size = 21)\n",
        "\n",
        "fig, axs = plt.subplots(3, 2, figsize=(15, 15))\n",
        "axs[0, 0].set_title(\"Level 0\")\n",
        "axs[0, 0].imshow(apple_stack[0] * 10)\n",
        "axs[1, 0].set_title(\"Level 2\")\n",
        "axs[1, 0].imshow(apple_stack[2] * 5)\n",
        "axs[2, 0].set_title(\"Level 4\")\n",
        "axs[2, 0].imshow(apple_stack[4])\n",
        "axs[0, 1].set_title(\"Level 0\")\n",
        "axs[0, 1].imshow(orange_stack[0] * 10)\n",
        "axs[1, 1].set_title(\"Level 2\")\n",
        "axs[1, 1].imshow(orange_stack[2] * 5)\n",
        "axs[2, 1].set_title(\"Level 4\")\n",
        "axs[2, 1].imshow(orange_stack[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diSCcSiNNLoJ"
      },
      "source": [
        "## 2.4 Multiresolution Blending"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oli2BHD6Gm6"
      },
      "source": [
        "Basically, we just take gaussian pyramid of the mask, and the stacks of the two images, and blend by the amount specified in the mask, adding them all to a matrix of zeros to get our final image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSa7Neui6D8s"
      },
      "source": [
        "def blend(positive, negative, mask, levels, g_std, k_size):\n",
        "  mask_stack = gaussian_stack(mask, levels, g_std, k_size)\n",
        "  negative_stack = laplacian_stack(negative, levels, g_std, k_size)\n",
        "  positive_stack = laplacian_stack(positive, levels, g_std, k_size)\n",
        "\n",
        "  image = np.zeros_like(mask)\n",
        "  for i in range(len(mask_stack)):\n",
        "    image += positive_stack[i] * mask_stack[i] + negative_stack[i] * (1 - mask_stack[i])\n",
        "\n",
        "  return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahpxmSau222f"
      },
      "source": [
        "Here is the mask that we are going to take the laplacian pyramid of and elementwise multiply by"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRrPhUeONMNR"
      },
      "source": [
        "mask = np.zeros_like(get_image('orange.jpeg'))\n",
        "for i in range(int(len(mask[0])/2)):\n",
        "  mask[:,i,:] = 1\n",
        "show(mask)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc8YtyPT6oi8"
      },
      "source": [
        "Done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoQuXUGz29mP"
      },
      "source": [
        "orange = get_image('orange.jpeg')/255\n",
        "apple = get_image('apple.jpeg')/255\n",
        "\n",
        "show(blend(apple, orange, mask, levels= 5, g_std = 2, k_size = 21))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnzPg0hm63Gj"
      },
      "source": [
        "Other Blends"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYx9ecdb6_dW"
      },
      "source": [
        "beautiful_world = get_image('beautiful_world.jpg')/255\n",
        "temple = get_image('temple.jpg')/255\n",
        "mask = np.zeros_like(beautiful_world)\n",
        "mask[:380, 200:550, :] = 1\n",
        "\n",
        "mask = np.pad(mask, ((0, 564), (0, 1020), (0, 0)))\n",
        "beautiful_world = np.pad(beautiful_world, ((0, 564), (0, 1020), (0, 0)))\n",
        "\n",
        "show(beautiful_world * mask)\n",
        "show(temple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_s2TfsR7e_5"
      },
      "source": [
        "levels= 5\n",
        "g_std = 4\n",
        "k_size = 21\n",
        "\n",
        "positive = beautiful_world\n",
        "negative = temple\n",
        "\n",
        "mask_stack = gaussian_stack(mask, levels, g_std * 2, k_size * 2 + 1)\n",
        "negative_stack = laplacian_stack(negative, levels, g_std, k_size)\n",
        "positive_stack = laplacian_stack(positive, levels, g_std, k_size)\n",
        "\n",
        "positive_masked_stack = []\n",
        "negative_masked_stack = []\n",
        "\n",
        "image = np.zeros_like(mask)\n",
        "for i in range(len(mask_stack)):\n",
        "  temp1 = positive_stack[i] * mask_stack[i]\n",
        "  positive_masked_stack.append(temp1)\n",
        "  temp2 = negative_stack[i] * (1 - mask_stack[i])\n",
        "  negative_masked_stack.append(temp2)\n",
        "  image += temp1 + temp2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEiLWGPCAaHG"
      },
      "source": [
        "fig, axs = fig, ax = plt.subplots(1, 5, figsize=(24, 50))\n",
        "for i in range(5):\n",
        "  axs[i].imshow(mask_stack[i], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHaAUuxd_ScX"
      },
      "source": [
        "show(image, figsize=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVDTtysSH2m4"
      },
      "source": [
        "beautiful_world = get_image('beautiful_world.jpg')/255\n",
        "miracles = get_image('miracles.jpg')/255\n",
        "mask = np.zeros_like(beautiful_world)\n",
        "mask[40:350, 220:510, :] = 1\n",
        "\n",
        "mask = np.pad(mask, ((0, 49), (210, 170), (0, 0)))\n",
        "beautiful_world = np.pad(beautiful_world, ((0, 49), (210, 170), (0, 0)))\n",
        "\n",
        "show(beautiful_world * mask)\n",
        "show(miracles)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn--WFruH2m4"
      },
      "source": [
        "levels= 5\n",
        "g_std = 4\n",
        "k_size = 21\n",
        "\n",
        "positive = beautiful_world\n",
        "negative = miracles\n",
        "\n",
        "mask_stack = gaussian_stack(mask, levels, g_std * 4, k_size * 4 + 1)\n",
        "negative_stack = laplacian_stack(negative, levels, g_std, k_size)\n",
        "positive_stack = laplacian_stack(positive, levels, g_std, k_size)\n",
        "\n",
        "positive_masked_stack = []\n",
        "negative_masked_stack = []\n",
        "\n",
        "image = np.zeros_like(mask)\n",
        "for i in range(len(mask_stack)):\n",
        "  temp1 = positive_stack[i] * mask_stack[i]\n",
        "  positive_masked_stack.append(temp1)\n",
        "  temp2 = negative_stack[i] * (1 - mask_stack[i])\n",
        "  negative_masked_stack.append(temp2)\n",
        "  image += temp1 + temp2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XN_yu43H2m4"
      },
      "source": [
        "fig, axs = fig, ax = plt.subplots(1, 5, figsize=(24, 50))\n",
        "for i in range(5):\n",
        "  axs[i].imshow(mask_stack[i], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAKrAIV-H2m5"
      },
      "source": [
        "show(image, figsize=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmZ1hYvHSOjf"
      },
      "source": [
        "fig, axs = fig, ax = plt.subplots(1, 5, figsize=(24, 50))\n",
        "for i in range(5):\n",
        "  axs[i].imshow(positive_masked_stack[i], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPKb0ea4SUXM"
      },
      "source": [
        "fig, axs = fig, ax = plt.subplots(1, 5, figsize=(24, 50))\n",
        "for i in range(5):\n",
        "  axs[i].imshow(negative_masked_stack[i], cmap = 'gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYKFgRqvQ2-O"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMKQMfckJBie"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}